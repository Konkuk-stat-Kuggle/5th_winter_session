{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a29f1f",
   "metadata": {},
   "source": [
    "# Entropy Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements, cnt = np.unique(target_col, return_counts = True)\n",
    "    entropy = -np.sum([(cnt[i] / np.sum(cnt))*np.log2(cnt[i] / np.sum(cnt)) for i in range(len(elements))])\n",
    "    return entropy\n",
    "\n",
    "def InfoGain(data, split_attribute_name, target_name):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    vals, cnt = np.unique(data[split_attibute_name], return_counts = True)\n",
    "    Weighted_Entropy = np.sum([(cnt[i] / np.sum(cnt))*entropy(data.where(data[split_attribute_name] == vals[i]).dropna()[target_name])\n",
    "                              for i in range((len(vals)))])\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain\n",
    "\n",
    "def ID3(data, original_data, features, target_attribute_name, parent_node_class = None):\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])\\\n",
    "                            [np.argmax(np.unique(data[target_attribute_name], return_counts = True))]\n",
    "        item_values = [InfoGain(data, feature, target_attribute_name) for feature in features]\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = featuers[best_feature_index]\n",
    "        \n",
    "        tree = {best_feature : {}}\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = ID3(sub_data, data, features, target_attribute_name, parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        return (tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f670d78",
   "metadata": {},
   "source": [
    "# Gini Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b06d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    return 1 - ((x / x.sum())**2).sum()\n",
    "\n",
    "def dt_gini(df):\n",
    "    G_lst, G1_lst, G2_lst, cp_lst = [], [], [], []\n",
    "    for feature in features:\n",
    "        df.sort_values(by = feature, inplace = True)\n",
    "        df.reset_index(drop = True, inplace = True)\n",
    "        cut_index = []\n",
    "        for i in range(len(df) - 1):\n",
    "            if df[\"target\"][i] != df[\"target\"][i + 1]:\n",
    "                cut_index.append(i)\n",
    "            else:\n",
    "                pass\n",
    "        for idx in cut_index:\n",
    "            cp = (df[feature][idx] + df[featuer][idx+1]) / 2\n",
    "            df_cp1 = df[df[feature] <= cp]\n",
    "            df_cp2 = df[df[feature] > cp]\n",
    "            N, N1, N2 = len(df), len(df_cp1), len(df_cp2)\n",
    "            G1, G2 = gini(df_cp1.target.value_counts()), gini(df_cp2.target.value_counts())\n",
    "            G = G1*(N1/N) + G2*(N2/N)\n",
    "            G_lst.append(G)\n",
    "            G1_lst.append(G1)\n",
    "            G2_lst.append(G2)\n",
    "            cp_lst.append(cp)\n",
    "        \n",
    "        num_cp.append(len(cut_index))\n",
    "    \n",
    "    key = np.argmin(G_lst)\n",
    "    \n",
    "    if key < num_cp[0]:\n",
    "        return featuers[0], cp_lst[key], min(G1_lst)\n",
    "    elif num_cp[0] <= key < sum(num_cp[:2]):\n",
    "        return featuers[1], cp_lst[key], min(G1_lst)\n",
    "    elif sum(num_cp[:2]) <= key < sum(num_cp[:3]):\n",
    "        return features[2], cp_lst[key], min(G1_lst)\n",
    "    elif sum(num_cp[:3]) <= key < min(G1_lst):\n",
    "        return features[3], cp_lst[key], min(G1_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5459285",
   "metadata": {},
   "source": [
    "# HardVoting vs SoftVoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80336e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = [0.6, 0.4]\n",
    "model_2 = [0.49, 0.51]\n",
    "model_3 = [0.49, 0.51]\n",
    "model_4 = [0.49, 0.51]\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4]\n",
    "\n",
    "def hard_voting(models):\n",
    "    class_0, class_1 = 0, 0\n",
    "    for model in models:\n",
    "        if model[0] < model[1]:\n",
    "            class_1 += 1\n",
    "        else:\n",
    "            class_0 += 1\n",
    "    if class_1 > class_0:\n",
    "        print(\"class 1\")\n",
    "    else:\n",
    "        print(\"class 0\")\n",
    "\n",
    "def soft_voting(models):\n",
    "    class_0, class_1 = 0, 0\n",
    "    for model in models:\n",
    "        if model[0] < model[1]:\n",
    "            class_1 += model[1]\n",
    "        else:\n",
    "            class_0 += model[0]\n",
    "    if class_1 > class_0:\n",
    "        print(\"class 1\")\n",
    "    else:\n",
    "        print(\"class 0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0dc1b947dce198ff7f2d2cb152b2cbb61132fce4429fa808fd5b89ac4d7df39fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
