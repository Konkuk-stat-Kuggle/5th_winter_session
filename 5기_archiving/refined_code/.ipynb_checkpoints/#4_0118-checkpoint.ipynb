{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = \"drive/MyDrive/dataset/kuggle/\"\n",
    "\n",
    "df_train = pd.read_csv(f\"{DataPath}Train.csv\")\n",
    "df_test = pd.read_csv(f\"{DataPath}Test.csv\")\n",
    "\n",
    "def outliers_iqr(data):\n",
    "    q1, q3 = np.percentile(data, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - (iqr * 1.5)\n",
    "    upper = q3 + (iqr * 1.5)\n",
    "\n",
    "    return np.where((data > upper) | (data < lower))\n",
    "\n",
    "df_train.drop(outliers_iqr(df_train.Age)[0], axis = 0, inplace = True)\n",
    "\n",
    "df_train.drop([\"ID\"], axis = 1, inplace = True)\n",
    "df_test.drop([\"ID\"], axis = 1, inplace = True)\n",
    "\n",
    "df_train.Work_Experience.fillna(0, inplace = True)\n",
    "df_train.Profession.fillna(\"JobLess\", inplace = True)\n",
    "\n",
    "df_test.Work_Experience.fillna(0, inplace = True)\n",
    "df_test.Profession.fillna(\"JobLess\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 존재하는 칼럼 : Ever_Married\n",
    "# 각 칼럼을 타겟으로 두고, 임의의 예측 모델을 생성\n",
    "# 예측값으로 결측치 대체\n",
    "\n",
    "#Ever_Married를 채우기 위한 임시 데이터 프레임으로 활용할 것\n",
    "df_1 = df_train.copy()\n",
    "\n",
    "#예측 모델을 돌리기 위해 임시 방편으로 결측치를 채워넣음\n",
    "df_1.Graduated.fillna(\"Yes\", inplace = True)\n",
    "df_1.Family_Size.fillna(2.0, inplace = True)\n",
    "df_1.Var_1.fillna(\"Cat_6\", inplace = True)\n",
    "\n",
    "#Ever_Married가 결측치인 행들만 모아서 새 데이터프레임으로 제작\n",
    "test_df_1 = df_1[df_1.Ever_Married.isna()]\n",
    "test_idx = test_df_1.index\n",
    "\n",
    "#Ever_Married가 결측치가 아닌 행들만 모아서 새 데이터프레임으로 제작\n",
    "train_df_1 = df_1.drop(test_idx, axis = 0)\n",
    "\n",
    "X_train_1 = train_df_1.drop([\"Ever_Married\"], axis = 1)\n",
    "X_test_1 = test_df_1.drop([\"Ever_Married\"], axis = 1)\n",
    "y_train_1 = train_df_1[\"Ever_Married\"]\n",
    "#y_test는 존재할 필요가 없음\n",
    "\n",
    "#결측치를 채우고 인코딩해야 결측치들이 사라지지 않음! 주의할 것!!\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Spending Score는 순서형 변수이기 때문에 LabelEncoding\n",
    "X_train_1.Spending_Score = encoder.fit_transform(X_train_1.Spending_Score)\n",
    "X_test_1.Spending_Score = encoder.fit_transform(X_test_1.Spending_Score)\n",
    "\n",
    "#나머지 변수는 OneHotEncoding을 진행\n",
    "X_train_1 = pd.get_dummies(X_train_1, columns = [\"Gender\", \"Graduated\", \"Profession\", \"Var_1\", \"Segmentation\"])\n",
    "X_test_1 = pd.get_dummies(X_test_1, columns = [\"Gender\", \"Graduated\", \"Profession\", \"Var_1\", \"Segmentation\"])\n",
    "\n",
    "#결측치를 채우는 모델은 임의로 랜덤포레스트로 지정함\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_1 = RandomForestClassifier()\n",
    "model_1.fit(X_train_1, y_train_1)\n",
    "prediction_1 = model_1.predict(X_test_1)\n",
    "\n",
    "#찢어놓은 데이터프레임을 복구하고, 예측치로 결측치를 대신함\n",
    "X_test_1[\"Ever_Married\"] = prediction_1\n",
    "X_train_1[\"Ever_Married\"] = y_train_1\n",
    "\n",
    "#인덱스를 초기화함으로서 데이터의 원본 순서를 복원할 수 있는 흔적을 남김\n",
    "X_train_1 = X_train_1.reset_index()\n",
    "X_test_1 = X_test_1.reset_index()\n",
    "\n",
    "#찢어놓은 데이터셋을 다시 맞춰주고, 순서를 복원함\n",
    "df_1 = pd.concat([X_train_1, X_test_1], axis = 0)\n",
    "df_1.sort_values(by = \"index\", inplace = True)\n",
    "df_1.set_index(\"index\", inplace = True)\n",
    "\n",
    "#완성\n",
    "# df_train.Ever_Married = df_1.Ever_Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c266b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 존재하는 칼럼 : Graduated\n",
    "# 각 칼럼을 타겟으로 두고, 임의의 예측 모델을 생성\n",
    "# 예측값으로 결측치 대체\n",
    "\n",
    "#Graduated 채우기 위한 임시 데이터 프레임으로 활용할 것\n",
    "df_2 = df_train.copy()\n",
    "\n",
    "#예측 모델을 돌리기 위해 임시 방편으로 결측치를 채워넣음\n",
    "df_2.Ever_Married.fillna(\"Yes\", inplace = True)\n",
    "df_2.Family_Size.fillna(2.0, inplace = True)\n",
    "df_2.Var_1.fillna(\"Cat_6\", inplace = True)\n",
    "\n",
    "#Graduated 결측치인 행들만 모아서 새 데이터프레임으로 제작\n",
    "test_df_2 = df_2[df_2.Graduated.isna()]\n",
    "test_idx_2 = test_df_2.index\n",
    "\n",
    "#Graduated가 결측치가 아닌 행들만 모아서 새 데이터프레임으로 제작\n",
    "train_df_2 = df_2.drop(test_idx_2, axis = 0)\n",
    "\n",
    "X_train_2 = train_df_2.drop([\"Graduated\"], axis = 1)\n",
    "X_test_2 = test_df_2.drop([\"Graduated\"], axis = 1)\n",
    "y_train_2 = train_df_2[\"Graduated\"]\n",
    "#y_test는 존재할 필요가 없음\n",
    "\n",
    "#결측치를 채우고 인코딩해야 결측치들이 사라지지 않음! 주의할 것!!\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Spending Score는 순서형 변수이기 때문에 LabelEncoding\n",
    "X_train_2.Spending_Score = encoder.fit_transform(X_train_2.Spending_Score)\n",
    "X_test_2.Spending_Score = encoder.fit_transform(X_test_2.Spending_Score)\n",
    "\n",
    "#Var_1에서 OneHotEncoding오류가 발생해 레이블 인코딩으로 수정함\n",
    "#Graduated가 결측치인 경우에 Var에서 Cat_7과 관련된 오류가 발생하는 것으로 예상됌\n",
    "X_train_2.Var_1 = encoder.fit_transform(X_train_2.Var_1)\n",
    "X_test_2.Var_1 = encoder.fit_transform(X_test_2.Var_1)\n",
    "\n",
    "#나머지 변수는 OneHotEncoding을 진행\n",
    "X_train_2 = pd.get_dummies(X_train_2, columns = [\"Gender\", \"Ever_Married\", \"Profession\", \"Segmentation\"])\n",
    "X_test_2 = pd.get_dummies(X_test_2, columns = [\"Gender\", \"Ever_Married\", \"Profession\", \"Segmentation\"])\n",
    "\n",
    "#결측치를 채우는 모델은 임의로 랜덤포레스트로 지정함\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_2 = RandomForestClassifier()\n",
    "model_2.fit(X_train_2, y_train_2)\n",
    "prediction_2 = model_2.predict(X_test_2)\n",
    "\n",
    "#찢어놓은 데이터프레임을 복구하고, 예측치로 결측치를 대신함\n",
    "X_test_2[\"Graduated\"] = prediction_2\n",
    "X_train_2[\"Graduated\"] = y_train_2\n",
    "\n",
    "#인덱스를 초기화함으로서 데이터의 원본 순서를 복원할 수 있는 흔적을 남김\n",
    "X_train_2 = X_train_2.reset_index()\n",
    "X_test_2 = X_test_2.reset_index()\n",
    "\n",
    "#찢어놓은 데이터셋을 다시 맞춰주고, 순서를 복원함\n",
    "df_2 = pd.concat([X_train_2, X_test_2], axis = 0)\n",
    "df_2.sort_values(by = \"index\", inplace = True)\n",
    "df_2.set_index(\"index\", inplace = True)\n",
    "\n",
    "#완성\n",
    "# df_train.Graduated = df_2.Graduated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 존재하는 칼럼 : Family_Size\n",
    "# 각 칼럼을 타겟으로 두고, 임의의 예측 모델을 생성\n",
    "# 예측값으로 결측치 대체\n",
    "\n",
    "#Family_Size를 채우기 위한 임시 데이터 프레임으로 활용할 것\n",
    "df_3 = df_train.copy()\n",
    "\n",
    "#예측 모델을 돌리기 위해 임시 방편으로 결측치를 채워넣음\n",
    "df_3.Graduated.fillna(\"Yes\", inplace = True)\n",
    "df_3.Ever_Married.fillna(\"Yes\", inplace = True)\n",
    "df_3.Var_1.fillna(\"Cat_6\", inplace = True)\n",
    "\n",
    "#Family_Size가 결측치인 행들만 모아서 새 데이터프레임으로 제작\n",
    "test_df_3 = df_3[df_3.Family_Size.isna()]\n",
    "test_idx = test_df_3.index\n",
    "\n",
    "#Family_Size가 결측치가 아닌 행들만 모아서 새 데이터프레임으로 제작\n",
    "train_df_3 = df_3.drop(test_idx, axis = 0)\n",
    "\n",
    "X_train_3 = train_df_3.drop([\"Family_Size\"], axis = 1)\n",
    "X_test_3 = test_df_3.drop([\"Family_Size\"], axis = 1)\n",
    "y_train_3 = train_df_3[\"Family_Size\"]\n",
    "#y_test는 존재할 필요가 없음\n",
    "\n",
    "#결측치를 채우고 인코딩해야 결측치들이 사라지지 않음! 주의할 것!!\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Spending Score는 순서형 변수이기 때문에 LabelEncoding\n",
    "X_train_3.Spending_Score = encoder.fit_transform(X_train_3.Spending_Score)\n",
    "X_test_3.Spending_Score = encoder.fit_transform(X_test_3.Spending_Score)\n",
    "\n",
    "#나머지 변수는 OneHotEncoding을 진행\n",
    "X_train_3 = pd.get_dummies(X_train_3, columns = [\"Gender\", \"Ever_Married\" ,\"Graduated\", \"Profession\", \"Var_1\", \"Segmentation\"])\n",
    "X_test_3 = pd.get_dummies(X_test_3, columns = [\"Gender\", \"Ever_Married\" ,\"Graduated\", \"Profession\", \"Var_1\", \"Segmentation\"])\n",
    "\n",
    "#결측치를 채우는 모델은 임의로 랜덤포레스트로 지정함\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(X_train_3, y_train_3)\n",
    "prediction_3 = model_3.predict(X_test_3)\n",
    "\n",
    "#찢어놓은 데이터프레임을 복구하고, 예측치로 결측치를 대신함\n",
    "X_test_3[\"Family_Size\"] = prediction_3\n",
    "X_train_3[\"Family_Size\"] = y_train_3\n",
    "\n",
    "#인덱스를 초기화함으로서 데이터의 원본 순서를 복원할 수 있는 흔적을 남김\n",
    "X_train_3 = X_train_3.reset_index()\n",
    "X_test_3 = X_test_3.reset_index()\n",
    "\n",
    "#찢어놓은 데이터셋을 다시 맞춰주고, 순서를 복원함\n",
    "df_3 = pd.concat([X_train_3, X_test_3], axis = 0)\n",
    "df_3.sort_values(by = \"index\", inplace = True)\n",
    "df_3.set_index(\"index\", inplace = True)\n",
    "\n",
    "#완성\n",
    "# df_train.Family_Size = df_3.Family_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 존재하는 칼럼 : Var_1\n",
    "# 각 칼럼을 타겟으로 두고, 임의의 예측 모델을 생성\n",
    "# 예측값으로 결측치 대체\n",
    "\n",
    "#Var_1를 채우기 위한 임시 데이터 프레임으로 활용할 것\n",
    "df_4 = df_train.copy()\n",
    "\n",
    "#예측 모델을 돌리기 위해 임시 방편으로 결측치를 채워넣음\n",
    "df_4.Graduated.fillna(\"Yes\", inplace = True)\n",
    "df_4.Family_Size.fillna(2.0, inplace = True)\n",
    "df_4.Ever_Married.fillna(\"Yes\", inplace = True)\n",
    "\n",
    "#Var_1가 결측치인 행들만 모아서 새 데이터프레임으로 제작\n",
    "test_df_4 = df_4[df_4.Var_1.isna()]\n",
    "test_idx = test_df_4.index\n",
    "\n",
    "#Var_1가 결측치가 아닌 행들만 모아서 새 데이터프레임으로 제작\n",
    "train_df_4 = df_4.drop(test_idx, axis = 0)\n",
    "\n",
    "X_train_4 = train_df_4.drop([\"Var_1\"], axis = 1)\n",
    "X_test_4 = test_df_4.drop([\"Var_1\"], axis = 1)\n",
    "y_train_4 = train_df_4[\"Var_1\"]\n",
    "#y_test는 존재할 필요가 없음\n",
    "\n",
    "#결측치를 채우고 인코딩해야 결측치들이 사라지지 않음! 주의할 것!!\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Spending Score는 순서형 변수이기 때문에 LabelEncoding\n",
    "X_train_4.Spending_Score = encoder.fit_transform(X_train_4.Spending_Score)\n",
    "X_test_4.Spending_Score = encoder.fit_transform(X_test_4.Spending_Score)\n",
    "\n",
    "#나머지 변수는 OneHotEncoding을 진행\n",
    "X_train_4 = pd.get_dummies(X_train_4, columns = [\"Gender\", \"Graduated\", \"Profession\", \"Ever_Married\" ,\"Segmentation\"])\n",
    "X_test_4 = pd.get_dummies(X_test_4, columns = [\"Gender\", \"Graduated\", \"Profession\", \"Ever_Married\", \"Segmentation\"])\n",
    "\n",
    "#결측치를 채우는 모델은 임의로 랜덤포레스트로 지정함\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_4 = RandomForestClassifier()\n",
    "model_4.fit(X_train_4, y_train_4)\n",
    "prediction_4 = model_4.predict(X_test_4)\n",
    "\n",
    "#찢어놓은 데이터프레임을 복구하고, 예측치로 결측치를 대신함\n",
    "X_test_4[\"Var_1\"] = prediction_4\n",
    "X_train_4[\"Var_1\"] = y_train_4\n",
    "\n",
    "#인덱스를 초기화함으로서 데이터의 원본 순서를 복원할 수 있는 흔적을 남김\n",
    "X_train_4 = X_train_4.reset_index()\n",
    "X_test_4 = X_test_4.reset_index()\n",
    "\n",
    "#찢어놓은 데이터셋을 다시 맞춰주고, 순서를 복원함\n",
    "df_4 = pd.concat([X_train_4, X_test_4], axis = 0)\n",
    "df_4.sort_values(by = \"index\", inplace = True)\n",
    "df_4.set_index(\"index\", inplace = True)\n",
    "\n",
    "#완성\n",
    "# df_train.Var_1 = df_4.Var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Ever_Married = df_1.Ever_Married\n",
    "df_train.Graduated = df_2.Graduated\n",
    "df_train.Family_Size = df_3.Family_Size\n",
    "df_train.Var_1 = df_4.Var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 데이터 인코딩하기\n",
    "#방법론은 결측치 채울 때와 동이랗며, 테스트 데이터셋에 대해서도 동일하게 진행\n",
    "df_train = pd.get_dummies(df_train, columns = [\"Gender\", \"Ever_Married\", \"Graduated\", \"Profession\", \"Var_1\"])\n",
    "df_test = pd.get_dummies(df_test, columns = [\"Gender\", \"Ever_Married\", \"Graduated\", \"Profession\", \"Var_1\"])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_train.Spending_Score = encoder.fit_transform(df_train.Spending_Score)\n",
    "df_test.Spending_Score = encoder.fit_transform(df_test.Spending_Score)\n",
    "\n",
    "#편의를 위해 인코딩 후, 칼럼 순서 변경할 것\n",
    "df_train = df_train[['Age', 'Work_Experience', 'Spending_Score', 'Family_Size',\n",
    "       'Gender_Female', 'Gender_Male', 'Ever_Married_No',\n",
    "       'Ever_Married_Yes', 'Graduated_No', 'Graduated_Yes',\n",
    "       'Profession_Artist', 'Profession_Doctor', 'Profession_Engineer',\n",
    "       'Profession_Entertainment', 'Profession_Executive',\n",
    "       'Profession_Healthcare', 'Profession_Homemaker', 'Profession_JobLess',\n",
    "       'Profession_Lawyer', 'Profession_Marketing', 'Var_1_Cat_1',\n",
    "       'Var_1_Cat_2', 'Var_1_Cat_3', 'Var_1_Cat_4', 'Var_1_Cat_5',\n",
    "       'Var_1_Cat_6', 'Var_1_Cat_7', 'Segmentation']]\n",
    "\n",
    "#JobLess는 트레인 데이터에 대해서, 결측치가 있을 경우 대체한 값이기 때문에 테스트 데이터에는 존재하지 않음\n",
    "#따라서 별개의 칼럼으로 제작해 추가했음\n",
    "# df_test[\"Profession_JobLess\"] = 0\n",
    "\n",
    "df_test = df_test[['Age', 'Work_Experience', 'Spending_Score', 'Family_Size',\n",
    "       'Gender_Female', 'Gender_Male', 'Ever_Married_No',\n",
    "       'Ever_Married_Yes', 'Graduated_No', 'Graduated_Yes',\n",
    "       'Profession_Artist', 'Profession_Doctor', 'Profession_Engineer',\n",
    "       'Profession_Entertainment', 'Profession_Executive',\n",
    "       'Profession_Healthcare', 'Profession_Homemaker',\n",
    "       'Profession_Lawyer', 'Profession_Marketing', 'Profession_JobLess' ,'Var_1_Cat_1',\n",
    "       'Var_1_Cat_2', 'Var_1_Cat_3', 'Var_1_Cat_4', 'Var_1_Cat_5',\n",
    "       'Var_1_Cat_6', 'Var_1_Cat_7', 'Segmentation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb648d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = setup(data = df_train, target = \"Segmentation\", train_size = 0.8)\n",
    "best5models = compare_models(sort = \"Accuracy\", n_select = 5, fold = 10)\n",
    "\n",
    "gbc = create_model(\"gbc\", fold = 10)\n",
    "tuned_gbc = tune_model(gbc, fold = 10, optimize = \"Accuracy\")\n",
    "\n",
    "catboost = create_model(\"catboost\", fold = 10)\n",
    "tuned_cat = tune_model(catboost, fold = 10, optimize = \"Accuracy\")\n",
    "\n",
    "lightgbm = create_model(\"lightgbm\", fold = 10)\n",
    "tuned_lgb = tune_model(lightgbm, fold = 10, optimize = \"Accuracy\")\n",
    "\n",
    "lr = create_model(\"lr\", fold = 10)\n",
    "tuned_lr = tune_model(lr, fold = 10, optimize = \"Accuracy\")\n",
    "\n",
    "tuned_set_1 = [tuned_gbc, tuned_cat, tuned_lgb]\n",
    "blended_1 = blend_models(estimator_list = tuned_set_1, fold = 10, method = \"soft\")\n",
    "\n",
    "tuned_set_2 = [tuned_gbc, tuned_cat, tuned_lgb, tuned_lr, tuned_ada]\n",
    "blended_2 = blend_models(estimator_list = tuned_set_2, fold = 10, method = \"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for model in tuned_set_2:\n",
    "    param_list.append(model.get_params())\n",
    "\n",
    "final_model = finalize_model(blended_2)\n",
    "predictions = predict_model(final_model, data = df_test)\n",
    "\n",
    "prep_pipe = get_config(\"prep_pipe\")\n",
    "prep_pipe.steps.append([\"trained_model\", final_model])\n",
    "pred = prep_pipe.predict_proba(df_test)\n",
    "\n",
    "prediction = []\n",
    "for i in range(len(pred)):\n",
    "    value = pred[i].max()\n",
    "    prediction.append(list(pred[i]).index(value))\n",
    "    \n",
    "encoder = {\"A\" : 0, \"B\" : 1, \"C\" : 2, \"D\" : 3}\n",
    "df_test.Segmentation = df_test.Segmentation.map(encoder)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == df_test.Segmentation[i]:\n",
    "        correct += 1\n",
    "\n",
    "acc = correct / len(prediction)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb888de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "  ccp_alpha = 0.0,\n",
    "  criterion = 'friedman_mse',\n",
    "  init = None,\n",
    "  learning_rate = 0.001,\n",
    "  loss = 'deviance',\n",
    "  max_depth = 8,\n",
    "  max_features = 'sqrt',\n",
    "  max_leaf_nodes = None,\n",
    "  min_impurity_decrease = 0.001,\n",
    "  min_impurity_split = None,\n",
    "  min_samples_leaf = 5,\n",
    "  min_samples_split = 7,\n",
    "  min_weight_fraction_leaf = 0.0,\n",
    "  n_estimators = 250,\n",
    "  n_iter_no_change = None,\n",
    "  presort = 'deprecated',\n",
    "  random_state = 8232,\n",
    "  subsample = 0.6,\n",
    "  tol = 0.0001,\n",
    "  validation_fraction = 0.1,\n",
    "  verbose = 0,\n",
    "  warm_start = False\n",
    ")\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "  depth = 2,\n",
    "  l2_leaf_reg = 2,\n",
    "  border_count = 254,\n",
    "  verbose = False,\n",
    "  random_strength = 0.2,\n",
    "  task_type = 'CPU',\n",
    "  n_estimators = 300,\n",
    "  random_state = 8232,\n",
    "  eta = 0.1\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "  boosting_type = 'gbdt',\n",
    "  colsample_bytree = 1.0,\n",
    "  importance_type = 'split',\n",
    "  dlearning_rated = 0.5,\n",
    "  dmax_depthd = -1,\n",
    "  dmin_child_samplesd = 86,\n",
    "  dmin_child_weightd = 0.001,\n",
    "  dmin_split_gaind = 0.4,\n",
    "  dn_estimatorsd = 130,\n",
    "  dnum_leavesd = 90,\n",
    "  dobjectived = None,\n",
    "  dreg_alphad = 0.15,\n",
    "  dreg_lambdad = 0.001,\n",
    "  dsilentd = 'dwarnd',\n",
    "  dsubsampled = 1.0,\n",
    "  dsubsample_for_bind = 200000,\n",
    "  dsubsample_freq = 0,\n",
    "  feature_fraction = 0.9,\n",
    "  bagging_freq = 7,\n",
    "  bagging_fraction  = 0.8\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "  C = 0.909,\n",
    "  class_weight = 'balanced',\n",
    "  dual = False,\n",
    "  fit_intercept = True,\n",
    "  intercept_scaling = 1,\n",
    "  l1_ratio = None,\n",
    "  max_iter = 1000,\n",
    "  multi_class = 'auto',\n",
    "  n_jobs = None,\n",
    "  penalty = 'l2',\n",
    "  random_state = 8232,\n",
    "  solver = 'lbfgs',\n",
    "  tol = 0.0001,\n",
    "  verbose = 0,\n",
    "  warm_start = False\n",
    ")\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "  algorithm = 'SAMME.R',\n",
    "  base_estimator = None,\n",
    "  learning_rate = 0.2,\n",
    "  n_estimators = 290,\n",
    "  random_state = 8232\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 모델의 accuracy 따른 가중치 적용\n",
    "models = {\n",
    "   'gbc': gbc.fit(X_train, y_train),\n",
    "   'cat': cat.fit(X_train, y_train),\n",
    "    'lgb': lgb.fit(X_train,y_train),\n",
    "    'lr': lr.fit(X_train,y_train),\n",
    "    'ada' : ada.fit(X_train,y_train),\n",
    "}\n",
    "\n",
    "# relative weights\n",
    "model_scores = {\n",
    "   name: accuracy_score(\n",
    "      y_test,\n",
    "      model.predict(X_test),\n",
    "      )\n",
    "   for name, model in models.items()\n",
    "}\n",
    "total_score = sum(model_scores.values())\n",
    "\n",
    "# combine the parts\n",
    "voting_ensemble = VotingClassifier(estimators = [(\"gbc\", gbc), (\"cat\", cat),\n",
    "                                              ('lgb',lgb),('lr',lr),('ada',ada)],\n",
    "                                   weights = [model_scores[name] / total_score for name in models.keys()],\n",
    "                                   voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63af4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(voting_ensemble, X, y, scoring = 'accuracy', cv = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0dc1b947dce198ff7f2d2cb152b2cbb61132fce4429fa808fd5b89ac4d7df39fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
